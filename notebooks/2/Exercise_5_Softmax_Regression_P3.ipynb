{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_xdi0AUN81t"
   },
   "source": [
    "# Softmax regression\n",
    "\n",
    "In this exercise you will train a softmax regression model to recognize handwritten digits.\n",
    "  \n",
    "The general setup is as follows:\n",
    "* we are given a set of pairs $(x, y)$, where $x \\in R^D$ is a vector of real numbers representing the features, and $y \\in \\{1,...,c\\}$ is the target (in our case we have ten classes, so $c=10$),\n",
    "* for a given $x$ we model the probability of $y=j$ by $$h(x)_j=p_j = \\frac{e^{w_j^Tx}}{\\sum_{i=1}^c e^{w_i^Tx}},$$\n",
    "* to find the right $w$ we will optimize the so called multiclass log loss:\n",
    "$$L(y,p) = \\log{p_y},$$\n",
    "$$J(w) = -\\frac{1}{n}\\sum_{i=1}^n L(y_i,h(x)),$$\n",
    "* with the loss function in hand we can improve our guesses iteratively:\n",
    "    * $w_{ij}^{t+1} = w_{ij}^t - \\text{step_size} \\cdot \\frac{\\partial J(w)}{\\partial w_{ij}}$,\n",
    "* we can end the process after some predefined number of epochs (or when the changes are no longer meaningful)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P3yuYp69N810"
   },
   "source": [
    "Let's start with importing the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ZOx1cckN814"
   },
   "outputs": [],
   "source": [
    "!wget -O mnist.npz https://s3.amazonaws.com/img-datasets/mnist.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cfggfnt5N82K"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def load_mnist(path='mnist.npz'):\n",
    "    with np.load(path) as f:\n",
    "        x_train, _y_train = f['x_train'], f['y_train']\n",
    "        x_test, _y_test = f['x_test'], f['y_test']\n",
    "        \n",
    "    x_train = x_train.reshape(-1, 28 * 28) / 255.\n",
    "    x_test = x_test.reshape(-1, 28 * 28) / 255.\n",
    "    \n",
    "    y_train = np.zeros((_y_train.shape[0], 10))\n",
    "    y_train[np.arange(_y_train.shape[0]), _y_train] = 1\n",
    "    \n",
    "    y_test = np.zeros((_y_test.shape[0], 10))\n",
    "    y_test[np.arange(_y_test.shape[0]), _y_test] = 1\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjFxWDLnN82X"
   },
   "source": [
    "Let's take a look at the data. In the \"x\" arrays you'll find the images (encoded as pixel intensities) and in the \"y\" ones you'll find the labels (one-hot encoded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxPEnhO_N82d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_train[:10])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yATia4LaN82n"
   },
   "source": [
    "Now let us see the data in a more human way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LXk-h0YuN82q"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = 20\n",
    "samples = range(num_samples)\n",
    "fig, subplots = plt.subplots(1, num_samples)\n",
    "fig.set_size_inches(15, 15)\n",
    "\n",
    "for i, s in enumerate(subplots.flatten()):\n",
    "    s.imshow(np.reshape(x_train[i, :], [28, 28]), cmap='gray')\n",
    "    s.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hgFd3QrRN82w"
   },
   "source": [
    "Next, we prepare $X$ and $y$ variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iQKol9KmN82z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 784)\n",
      "(4000, 10)\n"
     ]
    }
   ],
   "source": [
    "X = x_train[:4000]\n",
    "y = y_train[:4000]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JpAv_SngN83A"
   },
   "source": [
    "To train the model we will (obviously) use gradient descent. Inside the loop we need a method to compute the gradients. Let's start with implementing it, together with some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pUCxU7qEN83D"
   },
   "outputs": [],
   "source": [
    "# We will store the weights in a D x c matrix, where D is the number of features, and c is the number of classes\n",
    "#weights = (...) # TODO: Fill in, be sure to have the right shape!\n",
    "weights = np.zeros([X.shape[1], 10])\n",
    "\n",
    "\n",
    "#Softmax 1-D\n",
    "#Input : v(1,c) - vector from liniar classifier used on 1 sample\n",
    "#Output: probabilities of every class for sample pr(1,c)\n",
    "# Modifications: Numerical stability. Normalizaion for (potentially) large numbers used\n",
    "def softmax(z):\n",
    "    ########################################\n",
    "    # TODO: implement the softmax function #\n",
    "    ########################################\n",
    "    z -= np.max(z)\n",
    "    exp = np.exp(z)\n",
    "    return exp/np.sum(exp)\n",
    "\n",
    "\n",
    "#Predict: \n",
    "# m -number of samples\n",
    "# f - number of features\n",
    "# c - number of classes (we have digits, so we have 10 classes)\n",
    "#Input :w(784,c), X(m,f)\n",
    "#1)Dot product of X and w -> (m,c) - For every example we have classifier output (1,c)\n",
    "#2)Compute probabilities using softmax. softmax(M(m,c)) -> prob(m,c) - for every sample \n",
    "#  we have probability(1,10) of being of the class\n",
    "#Output: (m,c)\n",
    "def predict(w, X):\n",
    "    ###################################\n",
    "    # TODO: compute the probabilities #\n",
    "    ###################################\n",
    "    M = np.dot(X,w)\n",
    "    return np.apply_along_axis(softmax, axis=1, arr=M)\n",
    "\n",
    "def compute_loss_and_gradients(weights, X, y, l2_reg):\n",
    "    #############################################################################\n",
    "    # TODO: compute loss and gradients, don't forget to include regularization! #\n",
    "    #############################################################################\n",
    "    n_samples = X.shape[0]\n",
    "    pred = predict(weights,X)\n",
    "    y_arr  = y.argmax(axis=1)\n",
    "    prob = pred[range(n_samples),y_arr]\n",
    "    \n",
    "    loss = -(np.sum(np.log(prob))) + l2_reg * np.sum(weights **2)\n",
    "    \n",
    "    grad = pred.copy()\n",
    "    grad[range(n_samples),y_arr] -= 1\n",
    "    grad = grad/n_samples\n",
    "    grad = X.T.dot(grad)\n",
    "    grad -= 2 * l2_reg * weights\n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E65eXzFVN83Q"
   },
   "source": [
    "We are now in position to complete the training pipeline.\n",
    "\n",
    "If you have problems with convergence, be sure to check the gradients numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SyqXq54QN83W",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l2_reg = 0.5\n",
    "n_epochs = 250\n",
    "lr = 0.05\n",
    "\n",
    "losses = []\n",
    "for i in range(n_epochs):\n",
    "    loss, grad = compute_loss_and_gradients(weights, X, y, l2_reg)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    weights -= lr * grad\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZ5RVGfaN83j"
   },
   "source": [
    "Now compute your accuracy on the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WkPf223hN83q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 0.09871666666666666\n",
      "Test accuracy 0.098\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# TODO: compute the accuracy #\n",
    "##############################\n",
    "def accuracy(X,ground_truth):\n",
    "    pred = predict(weights,X)\n",
    "    return np.mean(pred.argmax(axis=1) == ground_truth.argmax(axis=1))\n",
    "    \n",
    "print(\"Training accuracy\", accuracy(x_train,y_train))\n",
    "print(\"Test accuracy\", accuracy(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rqcHaryrN83v"
   },
   "source": [
    "We can also visualize the weights learned by our algorithm. Try to anticipate the result before executing the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:44: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 0.8700166666666667\n",
      "Test accuracy 0.8766\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l2_reg = 0.01\n",
    "lr = 0.09\n",
    "losses = []\n",
    "epochs= 2\n",
    "batch_size = 128\n",
    "n_epochs = x_train.shape[0]//batch_size\n",
    "\n",
    "for j in range(epochs):\n",
    "    for i in range(n_epochs):\n",
    "        p = i * batch_size\n",
    "        q = p+batch_size\n",
    "        loss, grad = compute_loss_and_gradients(weights, x_train[p:q], y_train[p:q], l2_reg)\n",
    "        losses.append(loss)\n",
    "        weights -= lr * grad\n",
    "\n",
    "plt.plot(losses)\n",
    "\n",
    "print(\"Training accuracy\", accuracy(x_train,y_train))\n",
    "print(\"Test accuracy\", accuracy(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DC30gyHHN83y"
   },
   "outputs": [],
   "source": [
    "fig, subplots = plt.subplots(1, 10)\n",
    "fig.set_size_inches(15, 15)\n",
    "\n",
    "for i, s in enumerate(subplots.flatten()):\n",
    "    s.imshow(np.reshape(np.array(weights[:, i]), [28, 28]), cmap='gray')\n",
    "    s.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OsgljzA_N837"
   },
   "source": [
    "Note that we only used a small portion of the data to develop the model. Now, implement the training on full data. Also, validate your model properly and find a good value for `l2_reg` hyperparameter. Try to experiment with `batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tl8dXAPfN839"
   },
   "outputs": [],
   "source": [
    "################################################\n",
    "# TODO: implement the proper training pipeline #\n",
    "################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training pipeline<br/>\n",
    "1)Upload data. X and y<br/>\n",
    "2)Make train, test sets<br/>\n",
    "2.5)? Is cross-validation needed?<br/>\n",
    "3)create object of linear optimizer<br/>\n",
    "4)Grid_search on perameters<br/>\n",
    "5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def load_mnist(path='mnist.npz'):\n",
    "    with np.load(path) as f:\n",
    "        x_train, _y_train = f['x_train'], f['y_train']\n",
    "        x_test, _y_test = f['x_test'], f['y_test']\n",
    "        \n",
    "    x_train = x_train.reshape(-1, 28 * 28) / 255.\n",
    "    x_test = x_test.reshape(-1, 28 * 28) / 255.\n",
    "    \n",
    "    y_train = np.zeros((_y_train.shape[0], 10))\n",
    "    y_train[np.arange(_y_train.shape[0]), _y_train] = 1\n",
    "    \n",
    "    y_test = np.zeros((_y_test.shape[0], 10))\n",
    "    y_test[np.arange(_y_test.shape[0]), _y_test] = 1\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sft_regr import softmax_regression\n",
    "sft = softmax_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft.train(epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8953"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction =  sft.predict(x_test)\n",
    "accuracy(prediction,y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise_5_Softmax_Regression_P3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
