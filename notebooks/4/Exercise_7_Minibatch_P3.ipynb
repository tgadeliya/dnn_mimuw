{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ziZ9i7tXbO1T"
   },
   "source": [
    "In this lab, you should try to implement some of the techniques discussed in the lecture.\n",
    "Here is a list of reasonable tasks.\n",
    " \n",
    "Easy:\n",
    " * L1 or L2 regularization (choose one)\n",
    " * momentum, Nesterov's momentum (choose one)\n",
    "\n",
    "Medium difficulty:\n",
    " * Adagrad, RMSProp (choose one)\n",
    " * dropout\n",
    " * data augmentation (tiny rotatations, up/down-scalings etc.)\n",
    "\n",
    "Try to test your network to see if these changes improve accuracy. They improve accuracy much more if you increase the layer size, and if you add more layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P22HqX9AbO1a"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5_J1Q-ebO1y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-03-22 08:29:15--  https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.96.173\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.96.173|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11490434 (11M) [application/octet-stream]\n",
      "Saving to: ‘mnist.npz’\n",
      "\n",
      "mnist.npz           100%[===================>]  10,96M  3,04MB/s    in 4,3s    \n",
      "\n",
      "2019-03-22 08:29:19 (2,58 MB/s) - ‘mnist.npz’ saved [11490434/11490434]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O mnist.npz https://s3.amazonaws.com/img-datasets/mnist.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9jGPaZhbO2B"
   },
   "outputs": [],
   "source": [
    "# Let's read the mnist dataset\n",
    "\n",
    "def load_mnist(path='mnist.npz'):\n",
    "    with np.load(path) as f:\n",
    "        x_train, _y_train = f['x_train'], f['y_train']\n",
    "        x_test, _y_test = f['x_test'], f['y_test']\n",
    "        \n",
    "    x_train = x_train.reshape(-1, 28 * 28) / 255.\n",
    "    x_test = x_test.reshape(-1, 28 * 28) / 255.\n",
    "    \n",
    "    y_train = np.zeros((_y_train.shape[0], 10))\n",
    "    y_train[np.arange(_y_train.shape[0]), _y_train] = 1\n",
    "    \n",
    "    y_test = np.zeros((_y_test.shape[0], 10))\n",
    "    y_test[np.arange(_y_test.shape[0]), _y_test] = 1\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w3gAyqw4bO1p"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    # Derivative of the sigmoid\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FgEA2XRRbO2X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Accuracy: 0.1028\n",
      "Epoch: 1, Accuracy: 0.1028\n",
      "Epoch: 2, Accuracy: 0.1028\n",
      "Epoch: 3, Accuracy: 0.1028\n",
      "Epoch: 4, Accuracy: 0.1028\n",
      "Epoch: 5, Accuracy: 0.1028\n",
      "Epoch: 6, Accuracy: 0.1028\n",
      "Epoch: 7, Accuracy: 0.1028\n",
      "Epoch: 8, Accuracy: 0.1028\n",
      "Epoch: 9, Accuracy: 0.1028\n",
      "Epoch: 10, Accuracy: 0.1028\n",
      "Epoch: 11, Accuracy: 0.1028\n",
      "Epoch: 12, Accuracy: 0.1028\n",
      "Epoch: 13, Accuracy: 0.1028\n",
      "Epoch: 14, Accuracy: 0.1028\n",
      "Epoch: 15, Accuracy: 0.1028\n",
      "Epoch: 16, Accuracy: 0.1028\n",
      "Epoch: 17, Accuracy: 0.1028\n",
      "Epoch: 18, Accuracy: 0.1028\n",
      "Epoch: 19, Accuracy: 0.1028\n",
      "Epoch: 20, Accuracy: 0.1028\n",
      "Epoch: 21, Accuracy: 0.1028\n",
      "Epoch: 22, Accuracy: 0.1028\n",
      "Epoch: 23, Accuracy: 0.1028\n",
      "Epoch: 24, Accuracy: 0.1028\n",
      "Epoch: 25, Accuracy: 0.1028\n",
      "Epoch: 26, Accuracy: 0.1028\n",
      "Epoch: 27, Accuracy: 0.1028\n",
      "Epoch: 28, Accuracy: 0.1028\n",
      "Epoch: 29, Accuracy: 0.1028\n",
      "Epoch: 30, Accuracy: 0.1028\n",
      "Epoch: 31, Accuracy: 0.1028\n",
      "Epoch: 32, Accuracy: 0.1028\n",
      "Epoch: 33, Accuracy: 0.1028\n",
      "Epoch: 34, Accuracy: 0.1028\n",
      "Epoch: 35, Accuracy: 0.1028\n",
      "Epoch: 36, Accuracy: 0.1028\n",
      "Epoch: 37, Accuracy: 0.1028\n",
      "Epoch: 38, Accuracy: 0.1028\n",
      "Epoch: 39, Accuracy: 0.1028\n",
      "Epoch: 40, Accuracy: 0.1028\n",
      "Epoch: 41, Accuracy: 0.1028\n",
      "Epoch: 42, Accuracy: 0.1028\n",
      "Epoch: 43, Accuracy: 0.1028\n",
      "Epoch: 44, Accuracy: 0.1028\n",
      "Epoch: 45, Accuracy: 0.1028\n",
      "Epoch: 46, Accuracy: 0.1028\n",
      "Epoch: 47, Accuracy: 0.1028\n",
      "Epoch: 48, Accuracy: 0.1028\n",
      "Epoch: 49, Accuracy: 0.1028\n",
      "Epoch: 50, Accuracy: 0.1028\n",
      "Epoch: 51, Accuracy: 0.1028\n",
      "Epoch: 52, Accuracy: 0.1028\n",
      "Epoch: 53, Accuracy: 0.1028\n",
      "Epoch: 54, Accuracy: 0.1028\n",
      "Epoch: 55, Accuracy: 0.1028\n",
      "Epoch: 56, Accuracy: 0.1028\n",
      "Epoch: 57, Accuracy: 0.1028\n",
      "Epoch: 58, Accuracy: 0.1028\n",
      "Epoch: 59, Accuracy: 0.1028\n",
      "Epoch: 60, Accuracy: 0.1028\n",
      "Epoch: 61, Accuracy: 0.1028\n",
      "Epoch: 62, Accuracy: 0.1028\n",
      "Epoch: 63, Accuracy: 0.1028\n",
      "Epoch: 64, Accuracy: 0.1028\n",
      "Epoch: 65, Accuracy: 0.1028\n",
      "Epoch: 66, Accuracy: 0.1028\n",
      "Epoch: 67, Accuracy: 0.1028\n",
      "Epoch: 68, Accuracy: 0.1028\n",
      "Epoch: 69, Accuracy: 0.1028\n",
      "Epoch: 70, Accuracy: 0.1028\n",
      "Epoch: 71, Accuracy: 0.1028\n",
      "Epoch: 72, Accuracy: 0.1028\n",
      "Epoch: 73, Accuracy: 0.1028\n",
      "Epoch: 74, Accuracy: 0.1028\n",
      "Epoch: 75, Accuracy: 0.1028\n",
      "Epoch: 76, Accuracy: 0.1028\n",
      "Epoch: 77, Accuracy: 0.1028\n",
      "Epoch: 78, Accuracy: 0.1028\n",
      "Epoch: 79, Accuracy: 0.1028\n",
      "Epoch: 80, Accuracy: 0.1028\n",
      "Epoch: 81, Accuracy: 0.1028\n",
      "Epoch: 82, Accuracy: 0.1028\n",
      "Epoch: 83, Accuracy: 0.1028\n",
      "Epoch: 84, Accuracy: 0.1028\n",
      "Epoch: 85, Accuracy: 0.1028\n",
      "Epoch: 86, Accuracy: 0.1028\n",
      "Epoch: 87, Accuracy: 0.1028\n",
      "Epoch: 88, Accuracy: 0.1028\n",
      "Epoch: 89, Accuracy: 0.1028\n",
      "Epoch: 90, Accuracy: 0.1028\n",
      "Epoch: 91, Accuracy: 0.1028\n",
      "Epoch: 92, Accuracy: 0.1028\n",
      "Epoch: 93, Accuracy: 0.1028\n",
      "Epoch: 94, Accuracy: 0.1028\n",
      "Epoch: 95, Accuracy: 0.1028\n",
      "Epoch: 96, Accuracy: 0.1028\n",
      "Epoch: 97, Accuracy: 0.1028\n",
      "Epoch: 98, Accuracy: 0.1028\n",
      "Epoch: 99, Accuracy: 0.1028\n"
     ]
    }
   ],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, sizes):\n",
    "        # initialize biases and weights with random normal distr.\n",
    "        # weights are indexed by target node first\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) \n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "    def feedforward(self, a):\n",
    "        # Run the network on a batch\n",
    "        a = a.T\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.matmul(w, a)+b)\n",
    "        return a\n",
    "    \n",
    "    def update_mini_batch(self, mini_batch, eta, l2_reg):\n",
    "        # Update networks weights and biases by applying a single step\n",
    "        # of gradient descent using backpropagation to compute the gradient.\n",
    "        # The gradient is computed for a mini_batch which is as in tensorflow API.\n",
    "        # eta is the learning rate  \n",
    "        self.l2_reg = l2_reg\n",
    "        nabla_b, nabla_w = self.backprop(mini_batch[0].T,mini_batch[1].T) # CHANGE: Just one call!\n",
    "        \n",
    "        n = len(mini_batch[0])\n",
    "        #ADDED: 1-(l2_reg * eta)/len for L2_regularization\n",
    "        self.weights = [(1-(l2_reg*eta)/n)*w-eta*nw\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch[0]))*nb \n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "        \n",
    "    \n",
    "    def backprop(self, x, y):\n",
    "        # For a single input (x,y) return a pair of lists.\n",
    "        # First contains gradients over biases, second over weights.\n",
    "        g = x\n",
    "        gs = [g] # list to store all the gs, layer by layer\n",
    "        fs = [] # list to store all the fs, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            f = np.dot(w, g)+b\n",
    "            fs.append(f)\n",
    "            g = sigmoid(f)\n",
    "            gs.append(g)\n",
    "        # backward pass <- both steps at once\n",
    "        dLdg = self.cost_derivative(gs[-1], y)\n",
    "        dLdfs = []\n",
    "        for w,g in reversed(list(zip(self.weights,gs[1:]))):\n",
    "            dLdf = np.multiply(dLdg,np.multiply(g,1-g))\n",
    "            dLdfs.append(dLdf)\n",
    "            dLdg = np.matmul(w.T, dLdf)\n",
    "        \n",
    "        dLdWs = [np.matmul(dLdf,g.T) for dLdf,g in zip(reversed(dLdfs),gs[:-1])] # automatic here\n",
    "        dLdBs = [np.sum(dLdf,axis=1).reshape(dLdf.shape[0],1) for dLdf in reversed(dLdfs)] # CHANGE: Need to sum here\n",
    "        return (dLdBs,dLdWs)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        # Count the number of correct answers for test_data\n",
    "        pred = np.argmax(self.feedforward(test_data[0]),axis=0)\n",
    "        corr = np.argmax(test_data[1],axis=1).T\n",
    "        return np.mean(pred==corr)\n",
    "    \n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        return (output_activations-y) + np.sum(self.weights[-1])*self.l2_reg\n",
    "    \n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta, l2_reg, test_data=None):\n",
    "        x_train, y_train = training_data\n",
    "        if test_data:\n",
    "            x_test, y_test = test_data\n",
    "        for j in range(epochs):\n",
    "            for i in range(x_train.shape[0] // mini_batch_size):\n",
    "                x_mini_batch = x_train[(mini_batch_size*i):(mini_batch_size*(i+1))]\n",
    "                y_mini_batch = y_train[(mini_batch_size*i):(mini_batch_size*(i+1))]\n",
    "                self.update_mini_batch((x_mini_batch, y_mini_batch), eta, l2_reg)\n",
    "            if test_data:\n",
    "                print(\"Epoch: {0}, Accuracy: {1}\".format(j, self.evaluate((x_test, y_test))))\n",
    "            else:\n",
    "                print(\"Epoch: {0}\".format(j))\n",
    "\n",
    "\n",
    "network = Network([784,30,10])\n",
    "network.SGD((x_train, y_train), epochs=100, mini_batch_size=100, eta=3.0, l2_reg=0.0003, test_data=(x_test, y_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Exercise 7 - Minibatch P3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
